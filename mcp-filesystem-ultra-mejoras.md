# MCP Filesystem Ultra - Propuestas de Mejora

## üìã Contexto

Durante pruebas reales de uso del MCP filesystem-ultra, se identificaron limitaciones cr√≠ticas al trabajar con archivos grandes y b√∫squedas de ocurrencias espec√≠ficas.

### Caso de Uso Real que Fall√≥:
- **Tarea:** Cambiar la √∫ltima ocurrencia de 'CUMIEIRA' por 'ULTIMACUMIERA'
- **Problema:** Archivo con 31,248 l√≠neas y 106 ocurrencias totales
- **Limitaci√≥n:** No hay forma eficiente de:
  1. Leer un rango espec√≠fico de l√≠neas (ej: l√≠neas 26630-26680)
  2. Reemplazar solo la √∫ltima ocurrencia de un patr√≥n
  3. Acceder a l√≠neas espec√≠ficas por n√∫mero

---

## üéØ Propuestas de Mejora (Prioridad y Utilidad Real)

### **#1: `read_file_range` - CR√çTICO** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

**Funci√≥n:**
```json
{
  "tool": "read_file_range",
  "path": "archivo.sql",
  "start_line": 26630,
  "end_line": 26680
}
```

**Por qu√© es necesario:**
- `read_file` con `max_lines` solo lee desde el inicio (head), final (tail) o overview (all)
- No permite saltar a un rango espec√≠fico de l√≠neas
- Para archivos grandes, leer todo el archivo para ver 50 l√≠neas espec√≠ficas es ineficiente

**Caso de uso:**
- Ver contexto alrededor de la l√≠nea 26,645 en un archivo de 31,248 l√≠neas
- Inspeccionar errores en logs en l√≠neas espec√≠ficas
- Verificar cambios antes de editarlos

**Ahorro de tokens:** ~90% vs leer archivo completo

**Complejidad implementaci√≥n:** BAJA
- Similar a `read_file` pero con `sed -n 'start,endp'` o equivalente

---

### **#2: `replace_nth_occurrence` - CR√çTICO** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

**Funci√≥n:**
```json
{
  "tool": "replace_nth_occurrence",
  "path": "C:\\temp\\archivo.sql",
  "pattern": "CUMIEIRA",
  "replacement": "ULTIMACUMIERA",
  "occurrence": -1,              // -1 = √∫ltima, 1 = primera, 2 = segunda, etc.
  "recursive": false             // opcional: buscar en directorio
}
```

**Por qu√© es necesario:**
- `search_and_replace` reemplaza TODAS las ocurrencias
- No hay forma de reemplazar solo la primera, √∫ltima o N-√©sima ocurrencia
- Casos reales requieren precisi√≥n quir√∫rgica

**Casos de uso:**
- Cambiar solo la √∫ltima entrada en un log
- Actualizar solo la primera definici√≥n de una variable
- Modificar ocurrencia espec√≠fica sin tocar las dem√°s

**Ahorro de tokens:** ~80% vs leer ‚Üí analizar ‚Üí editar manualmente

**Complejidad implementaci√≥n:** MEDIA
- Requiere contar ocurrencias
- Identificar l√≠nea espec√≠fica
- Aplicar reemplazo solo en esa l√≠nea

---

### **#3: `advanced_text_search` mejorado** ‚≠ê‚≠ê‚≠ê‚≠ê

**Mejoras propuestas:**
```json
{
  "tool": "advanced_text_search",
  "path": "archivo.sql",
  "pattern": "CUMIEIRA",
  "show_context": true,          // NUEVO: mostrar l√≠neas antes/despu√©s
  "context_lines": 2,             // NUEVO: cu√°ntas l√≠neas de contexto
  "return_mode": "last"           // NUEVO: "all", "first", "last"
}
```

**Salida mejorada:**
```
Match #53 (last) at line 26645 in C:\temp\insert_portugal_final.sql:
26643: ('PT', '5040-321', 'SANTA MARTA DE PENAGUI√ÉO', 'Fontelas'...
26644: ('PT', '5040-322', 'SANTA MARTA DE PENAGUI√ÉO', 'Fornelos'...
26645: ('PT', '5040-323', 'CUMIEIRA', 'Vale da Cumieira'...
26646: ('PT', '5040-324', 'SANTA MARTA DE PENAGUI√ÉO', 'Galegas'...
26647: ('PT', '5040-325', 'SANTA MARTA DE PENAGUI√ÉO', 'Gondar√©m'...
```

**Por qu√© es necesario:**
- Actualmente solo muestra: `archivo.sql:123` sin contenido
- No permite ver contexto
- No permite filtrar primera/√∫ltima ocurrencia f√°cilmente

**Ahorro de tokens:** ~60% vs buscar + leer archivo

**Complejidad implementaci√≥n:** BAJA

---

## üìä Comparativa de Prioridades

| Funci√≥n | Impacto | Ahorro Tokens | Complejidad | Prioridad |
|---------|---------|---------------|-------------|-----------|
| `read_file_range` | üî•üî•üî•üî•üî• | 90% | Baja | **CR√çTICA** |
| `replace_nth_occurrence` | üî•üî•üî•üî•üî• | 80% | Media | **CR√çTICA** |
| `advanced_text_search` mejorado | üî•üî•üî•üî• | 60% | Baja | Alta |

---

## üîß Implementaci√≥n Sugerida

### Para `read_file_range`:

**Pseudoc√≥digo:**
```rust
fn read_file_range(path: String, start_line: usize, end_line: usize) -> Result<String> {
    let file = File::open(path)?;
    let reader = BufReader::new(file);
    
    let lines: Vec<String> = reader
        .lines()
        .enumerate()
        .filter(|(i, _)| *i >= start_line && *i <= end_line)
        .map(|(_, line)| line.unwrap())
        .collect();
    
    Ok(lines.join("\n"))
}
```

**Alternativa con comando shell:**
```bash
sed -n '${start_line},${end_line}p' "${path}"
```

---

### Para `replace_nth_occurrence`:

**Pseudoc√≥digo:**
```rust
fn replace_nth_occurrence(
    path: String, 
    pattern: String, 
    replacement: String, 
    occurrence: i32
) -> Result<String> {
    let content = read_file(&path)?;
    let lines: Vec<String> = content.lines().map(|s| s.to_string()).collect();
    
    let mut matches: Vec<usize> = lines
        .iter()
        .enumerate()
        .filter(|(_, line)| line.contains(&pattern))
        .map(|(i, _)| i)
        .collect();
    
    if matches.is_empty() {
        return Err("Pattern not found");
    }
    
    let target_index = if occurrence == -1 {
        matches.len() - 1  // √∫ltima
    } else if occurrence > 0 {
        (occurrence as usize) - 1  // N-√©sima (1-indexed)
    } else {
        return Err("Invalid occurrence value");
    };
    
    if target_index >= matches.len() {
        return Err("Occurrence out of range");
    }
    
    let line_number = matches[target_index];
    lines[line_number] = lines[line_number].replace(&pattern, &replacement);
    
    write_file(&path, lines.join("\n"))?;
    Ok(format!("Replaced at line {}", line_number + 1))
}
```

---

## üß™ Casos de Prueba

### Test 1: `read_file_range`
```json
Input:
{
  "path": "archivo.txt",  // 1000 l√≠neas
  "start_line": 450,
  "end_line": 460
}

Expected: Solo l√≠neas 450-460 (11 l√≠neas)
Tokens: ~100 vs ~8000 (leer todo)
```

### Test 2: `replace_nth_occurrence`
```json
Input:
{
  "path": "test.sql",
  "pattern": "CUMIEIRA",
  "replacement": "NUEVA",
  "occurrence": -1  // √∫ltima
}

Archivo tiene 5 CUMIEIRA en l√≠neas: 10, 25, 50, 100, 150
Expected: Solo cambia l√≠nea 150
```

### Test 3: `replace_nth_occurrence` - primera
```json
Input:
{
  "occurrence": 1  // primera
}

Expected: Solo cambia l√≠nea 10
```

---

## üìù Notas Adicionales

### Por qu√© NO usar Bash como soluci√≥n:
- El contenedor de Claude Desktop **no tiene acceso** a `/mnt/c/`
- Confirmado durante pruebas: `ls /mnt/c/temp/*.sql` ‚Üí "No such file or directory"
- Bash no es confiable como fallback

### Alternativas descartadas:
- ‚ùå `find_last_occurrence` - Redundante si `advanced_text_search` se mejora
- ‚ùå `edit_file_by_line` - `replace_nth_occurrence` es m√°s vers√°til
- ‚ùå `replace_at_line` - Cubierto por `replace_nth_occurrence`

---

## üéØ Conclusi√≥n

**2 funciones cr√≠ticas** que resolver√≠an el 90% de limitaciones actuales:

1. **`read_file_range`** - Lectura eficiente de rangos espec√≠ficos
2. **`replace_nth_occurrence`** - Reemplazos precisos (primera/√∫ltima/N-√©sima)

Con estas mejoras, el MCP filesystem-ultra ser√≠a significativamente m√°s eficiente para:
- Archivos grandes (>10,000 l√≠neas)
- B√∫squedas y reemplazos precisos
- Workflows de an√°lisis y edici√≥n
- Ahorro masivo de tokens

---

**Documento generado:** 2025-10-25  
**Basado en:** Pruebas reales de uso con archivos SQL de 31K+ l√≠neas
