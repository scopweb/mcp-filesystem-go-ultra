# Claude Memory - MCP Filesystem Ultra (v3.1.0)
# Token-Efficient Workflows for Editing Operations

## Quick Summary
This MCP provides 35+ tools for efficient file operations. Key optimizations:
- Bug #5 (v3.1.0): Surgical edits reduce token usage by 70-80%
- Use smart_search + read_file_range + edit_file instead of read_file + write_file
- Context validation prevents stale edits
- Real-time telemetry monitors edit efficiency

## Critical Workflow Rules

### NEVER DO THIS (Token Waste)
❌ read_file("large_file.go")           # Reads entire 5000-line file (~125k tokens)
❌ write_file("large_file.go", content) # Rewrites entire file (~125k tokens)
TOTAL: 250k+ tokens wasted

### ALWAYS DO THIS (99% Token Savings)
✅ smart_search("large_file.go", "func ProcessData")  # Find location (~500 tokens)
✅ read_file_range("large_file.go", 156, 189)        # Read 34 lines (~850 tokens)
✅ edit_file("large_file.go", old_snippet, new_snippet) # Surgical edit (~500 tokens)
TOTAL: ~2k tokens (98% savings)

## Core Tools for Efficient Editing

### 1. LOCATE CODE (smart_search)
Usage: Find exact line numbers before reading file
Input: file path + pattern
Output: Line numbers in format "lines 45-67"
Token cost: ~500 tokens
Example: Searching for function definitions in 5000-line file

### 2. READ TARGETED SECTION (read_file_range)
Usage: Read ONLY the lines you need (never the whole file)
Input: file path + start_line + end_line
Output: Exact lines (context preserved)
Token cost: ~850 tokens for 34 lines
Rule: Always use after smart_search to get line numbers

### 3. EDIT SURGICALLY (edit_file)
Usage: Replace text in context (safer than write_file)
Input: file path + old_text + new_text
Output: Replacement count + confidence level
Important: Includes automatic context validation (detects file changes)
Error: "context validation failed" = file modified externally, must re-read
Token cost: ~500 tokens

### 4. MONITOR PATTERNS (get_edit_telemetry) [NEW in v3.1.0]
Usage: See if you're editing efficiently
Input: None
Output: JSON with statistics
- total_edits: Count of all edits
- targeted_edits: Surgical edits <100 bytes (good!)
- full_rewrites: Large edits >1000 bytes (inefficient)
- targeted_percent: Percentage of surgical edits (goal: >80%)
- recommendation: Auto-generated advice
Token cost: ~200 tokens
When to use: Periodically check patterns, especially after large edit sessions

## File Size Guidelines

### Small Files (<1000 lines)
Can use: read_file() directly
Tokens: Acceptable overhead

### Medium Files (1000-5000 lines)
MUST use: smart_search + read_file_range + edit_file
Example: 3000-line file
- smart_search: 500 tokens (find location)
- read_file_range: 1200 tokens (read 50 lines)
- edit_file: 500 tokens
- Total: 2200 tokens vs 75k+ if you read entire file

### Large Files (>5000 lines)
CRITICAL: Never use read_file() on these
Min workflow: smart_search → read_file_range → edit_file
Token savings: 95-98%

## Error Messages & Recovery

### "context validation failed: surrounding context doesn't match"
Meaning: File changed since you read it (another editor modified it)
Solution: Re-run smart_search + read_file_range to get fresh content
Prevents: Data corruption from stale edits

### "no match found for old_text"
Meaning: The exact text you're searching for doesn't exist
Solutions:
1. Use smart_search to find actual text
2. Check for whitespace/formatting differences
3. Use count_occurrences to verify text exists

### "multiple matches found for old_text"
Meaning: Same text appears multiple times
Use: replace_nth_occurrence() with occurrence parameter
- occurrence: 1 (first), 2 (second), -1 (last), -2 (penultimate)

## Advanced Tools (Context Optimization)

### count_occurrences
Purpose: Count pattern matches without reading full file
Saves: 95% tokens vs reading entire file
When: Need to verify multiple occurrences exist

### replace_nth_occurrence
Purpose: Change ONLY the 1st, 2nd, or last occurrence
Saves: 99.8% tokens (surgical precision)
When: Multiple matches but you need specific one

### read_file_range
Purpose: Extract lines N to M efficiently
Important: Returns full context (surrounding lines)
When: You know exact line numbers from smart_search

## Batch Operations

### What batch_operations Supports
✅ copy: Duplicate files/directories
✅ delete: Remove files/directories
✅ create: Make new files

### When NOT to Use
❌ Don't batch unrelated operations (decreases clarity)
✅ DO batch: Related file operations in same directory

## Token Budgeting

### Per-Session Estimates
- Average edit session:
  - 5 edits with new workflow: ~12k tokens
  - 5 edits with old workflow: ~250k tokens
  - SAVINGS: 238k tokens per session

### New User: Monitor First Week
- Day 1-2: Use telemetry to establish baseline
- Day 3-5: Optimize based on patterns
- Week 2: Should see >80% targeted_edits ratio

## Context Validation Deep Dive

### What It Does
1. When you call edit_file(), it checks surrounding lines
2. Compares with file currently on disk
3. If mismatch detected: FAILS SAFELY (no corruption)
4. Returns clear error message

### Example Scenario
❌ BAD:
1. read_file("engine.go") at 10:00 AM
2. [15 minutes pass, someone else edits engine.go]
3. edit_file() at 10:15 AM → FAILS with validation error ✓ (good!)
4. You re-read with smart_search + read_file_range → fresh content
5. edit_file() succeeds ✓

Why this matters: Prevents overwriting someone else's work

## Telemetry Interpretation

### Healthy Pattern (>80% targeted_edits)
{
  "targeted_edits": 24,
  "full_rewrites": 6,
  "targeted_percent": "80%",
  "recommendation": "Good! Edits are efficient. Continue using smart_search + read_file_range + edit_file workflow"
}

### Problem Pattern (<50% targeted_edits)
{
  "targeted_edits": 10,
  "full_rewrites": 15,
  "targeted_percent": "40%",
  "recommendation": "Consider using smart_search + read_file_range for more precise edits"
}

## Feature Reference (v3.1.0 = 35 tools)

Core Tools:
- read_file, write_file, edit_file
- read_file_range (v3.1.0)
- count_occurrences (v3.1.0)
- replace_nth_occurrence (v3.1.0)

Search Tools:
- smart_search, advanced_text_search

Directory Tools:
- list_directory, create_directory, delete_directory, move_directory

File Operations:
- copy_file, move_file, delete_file, create_file

Batch Operations:
- batch_operations (supports copy, delete, create)

Metrics & Monitoring:
- get_edit_telemetry (v3.1.0) [NEW]

Plus 16+ additional metadata and utility tools

## ONE-MINUTE SUMMARY
1. Find code location: smart_search()
2. Read only what you need: read_file_range()
3. Edit surgically: edit_file()
4. Monitor efficiency: get_edit_telemetry()
5. If edit fails: context validation error = file changed, re-read
6. Goal: >80% targeted_edits, <20% full_rewrites

## Debug Mode

Run server with debug enabled:
```
mcp-filesystem-ultra.exe --debug
```

See: Tool execution details, validation checks, telemetry logging

## Performance Impact of Bug #5 Fixes

v3.0 → v3.1.0 Changes:
- Phase 1: Documentation guidance = 40% efficiency improvement
- Phase 2: Line numbers in search (already existed) = 20% improvement
- Phase 3: Context validation = 15% error reduction
- Phase 4: Telemetry monitoring = 100% visibility

Combined Impact: 70-80% token reduction for typical edit workflows

Example: 5000-line file edit
- Before v3.1.0: 150k+ tokens per edit
- After v3.1.0: 2-5k tokens per edit
- TOTAL SAVINGS: 97-98%
