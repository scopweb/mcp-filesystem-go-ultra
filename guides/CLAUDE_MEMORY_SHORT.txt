# MCP Filesystem Ultra - Claude Desktop Quick Reference (v3.1.0)

## ⚡ CRITICAL RULES (ALWAYS FOLLOW)

**NEVER** read entire large files with read_file() → wasteful
**MUST** use: smart_search() → read_file_range() → edit_file()
**MUST** check file size: <1000 lines = ok | >1000 lines = ALWAYS use workflow
**MUST** validate context: if edit fails, file changed externally, re-read it

---

## The One Rule: Surgical Edits Save 98% Tokens

### ❌ WASTEFUL (Avoid)
read_file(large_file) → write_file(large_file)
Example: 5000-line file = 250k+ tokens

### ✅ EFFICIENT (Always Use)
smart_search(file, pattern) → read_file_range(start, end) → edit_file(old, new)
Example: 5000-line file = 2k tokens (98% savings)

---

## The 4-Step Workflow

1. **smart_search(file, pattern)**
   - Find exact location → returns "lines 45-67"

2. **read_file_range(file, start_line, end_line)**
   - Read ONLY needed lines → never read entire file

3. **edit_file(file, old_text, new_text)**
   - Replace surgically → includes context validation
   - ERROR: "context validation failed" = file changed externally, re-read

4. **get_edit_telemetry()** (optional)
   - Monitor if you're editing efficiently (goal: >80% targeted_edits)

---

## File Size Rules

| Size | Tool | Why |
|------|------|-----|
| <1000 lines | read_file() | OK |
| 1000-5000 lines | smart_search + read_file_range + edit_file | MUST DO |
| >5000 lines | smart_search + read_file_range + edit_file | CRITICAL |

---

## When Edits Fail

**"context validation failed"** = File changed since you read it
→ Re-run: smart_search() + read_file_range() to get fresh content

**"no match found"** = Text doesn't exist
→ Use smart_search() first to verify location

**"multiple matches found"** = Same text appears N times
→ Use replace_nth_occurrence(file, pattern, new_text, occurrence=-1)

---

## Advanced Tools (When Needed)

- **count_occurrences** - Count matches without reading file (95% token savings)
- **replace_nth_occurrence** - Change only 1st, 2nd, or last match (99.8% savings)

---

## Key Metrics

- Targeted edit: <100 bytes (good ✅)
- Full rewrite: >1000 bytes (inefficient ⚠️)
- Goal: >80% targeted_edits via get_edit_telemetry()

---

## Token Budgeting Example

5 edits in a session:
- Old way: ~250k tokens
- New way: ~12k tokens
- SAVINGS: 238k tokens per session

---

## All 36 Tools Available

Core: read_file, write_file, edit_file, read_file_range, count_occurrences, replace_nth_occurrence, intelligent_write, intelligent_read, intelligent_edit
Search: smart_search, advanced_text_search
Files: copy_file, move_file, delete_file
Dirs: list_directory, create_directory, delete_directory, rename_file
Batch: batch_operations
Monitor: get_edit_telemetry
Analysis: analyze_file, analyze_write, analyze_edit, analyze_delete
Plus 17+ utility tools (artifacts, stats, info, recovery, etc)
