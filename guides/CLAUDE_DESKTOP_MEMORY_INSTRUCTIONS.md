# Instrucciones de Memoria para Claude Desktop

## üìã Copia y Pega Esto en la Memoria Personalizada de Claude Desktop

---

## MCP Filesystem Ultra-Fast v3.0 - Instrucciones de Uso Eficiente

### üéØ Principios Clave de Optimizaci√≥n de Tokens

1. **SIEMPRE usa `max_lines` al leer archivos grandes**
   - Para archivos >100 l√≠neas, NUNCA leas todo el archivo
   - Empieza con 50 l√≠neas, incrementa solo si necesitas m√°s
   - Usa `mode` apropiado: head, tail, o all

2. **Lectura Progresiva** - Estrategia de 3 pasos:
   ```
   Paso 1: Lee 20-50 l√≠neas para contexto inicial
   Paso 2: Si necesitas m√°s, lee 100 l√≠neas
   Paso 3: Solo lee archivo completo si es absolutamente necesario
   ```

3. **Operaciones en Lote** - Para cambios m√∫ltiples:
   - Usa `batch_operations` en lugar de operaciones individuales
   - Siempre con `atomic: true` para seguridad
   - Valida primero con `validate_only: true`

### üìñ Herramientas Disponibles (32 total)

#### Lectura de Archivos (Prioridad: OPTIMIZACI√ìN DE TOKENS)

**`read_file`** - Lectura principal (USA SIEMPRE max_lines)
```json
{
  "path": "archivo.txt",
  "max_lines": 50,        // OBLIGATORIO para archivos >100 l√≠neas
  "mode": "head"          // "head", "tail", o "all"
}
```

**Cu√°ndo usar cada modo:**
- `mode: "head"` ‚Üí Ver inicio de logs, inicio de c√≥digo, configuraciones
- `mode: "tail"` ‚Üí Ver final de logs, √∫ltimos resultados, outputs
- `mode: "all"` ‚Üí Overview r√°pido (muestra inicio + final con gap en medio)

**`intelligent_read`** - Auto-selecciona estrategia √≥ptima
- √ösalo cuando no est√©s seguro del tama√±o
- Autom√°ticamente usa chunking para archivos >50KB

**`chunked_read_file`** - Para archivos gigantes (>1MB)
- Solo cuando sepas que el archivo es enorme

#### Escritura de Archivos

**`write_file`** - Escritura est√°ndar (archivos <50KB)

**`intelligent_write`** - Auto-optimiza (RECOMENDADO)
- Usa esto por defecto
- Detecta tama√±o y elige mejor estrategia

**`streaming_write_file`** - Para archivos muy grandes (>1MB)

#### Edici√≥n de Archivos

**`edit_file`** - Edici√≥n est√°ndar
- Para archivos peque√±os/medianos

**`intelligent_edit`** - Edici√≥n optimizada (RECOMENDADO)
- Usa esto por defecto
- Auto-selecciona mejor estrategia

**`recovery_edit`** - Cuando edit_file falla
- Fuzzy matching autom√°tico
- Normalizaci√≥n de espacios
- 95% de √©xito vs fallos comunes

#### Operaciones en Lote (NUEVO v2.6)

**`batch_operations`** - Operaciones at√≥micas
```json
{
  "request_json": "{
    \"operations\": [
      {\"type\": \"write\", \"path\": \"file1.txt\", \"content\": \"...\"},
      {\"type\": \"edit\", \"path\": \"file2.txt\", \"old_text\": \"...\", \"new_text\": \"...\"},
      {\"type\": \"move\", \"source\": \"old.txt\", \"destination\": \"new.txt\"}
    ],
    \"atomic\": true,
    \"create_backup\": true,
    \"validate_only\": false
  }"
}
```

**Cu√°ndo usar:**
- Refactoring de m√∫ltiples archivos
- Reorganizaci√≥n de proyectos
- Cambios que deben ser todo-o-nada

**IMPORTANTE:** Siempre valida primero:
```json
{"validate_only": true}  // Paso 1: Validar
{"validate_only": false} // Paso 2: Ejecutar si validaci√≥n OK
```

#### Plan Mode / Dry-Run (v2.5)

**`analyze_write`** - Analiza escritura sin ejecutar
**`analyze_edit`** - Analiza edici√≥n sin ejecutar
**`analyze_delete`** - Analiza eliminaci√≥n sin ejecutar

**Cu√°ndo usar:**
- Antes de operaciones cr√≠ticas
- Para verificar qu√© se va a cambiar
- Para evaluar riesgos

#### B√∫squeda

**`smart_search`** - B√∫squeda por nombre/contenido
**`advanced_text_search`** - B√∫squeda avanzada con contexto
**`search_and_replace`** - B√∫squeda y reemplazo recursivo

#### Gesti√≥n de Archivos

**`list_directory`** - Listar directorio
**`create_directory`** - Crear directorio
**`delete_file`** - Eliminar permanentemente (¬°CUIDADO!)
**`soft_delete_file`** - Eliminar a carpeta trash (SEGURO)
**`move_file`** - Mover/renombrar
**`copy_file`** - Copiar archivo/directorio
**`rename_file`** - Renombrar
**`get_file_info`** - Informaci√≥n detallada

#### An√°lisis y Optimizaci√≥n

**`analyze_file`** - Analiza archivo y sugiere estrategia
**`get_optimization_suggestion`** - Recomendaci√≥n de herramienta √≥ptima
**`performance_stats`** - Estad√≠sticas de rendimiento

### üéØ Workflows Recomendados

#### Workflow 1: Leer Archivo Grande para An√°lisis
```
1. get_file_info("archivo.log")           // Ver tama√±o
2. read_file("archivo.log", max_lines=50, mode="head")  // Contexto inicial
3. Si necesitas m√°s ‚Üí read_file(..., max_lines=100)
4. Solo si absolutamente necesario ‚Üí read_file sin l√≠mites
```

#### Workflow 2: Refactoring Multi-Archivo
```
1. Identifica archivos afectados
2. batch_operations con validate_only=true  // Validar
3. Revisa el an√°lisis
4. batch_operations con validate_only=false // Ejecutar
```

#### Workflow 3: Edici√≥n con Seguridad
```
1. analyze_edit(path, old_text, new_text)  // Dry-run
2. Revisa el an√°lisis de riesgo
3. Si es seguro ‚Üí edit_file o intelligent_edit
4. Si falla ‚Üí recovery_edit (fuzzy matching)
```

#### Workflow 4: Operaci√≥n Cr√≠tica
```
1. analyze_delete(path)  // Ver impacto
2. Si riesgoso ‚Üí usa soft_delete_file en lugar de delete_file
3. Si procedes ‚Üí batch_operations con backup
```

### ‚ùå Antipatrones - EVITA ESTOS ERRORES

**‚ùå NO HAGAS:**
```json
// Leer archivo completo sin l√≠mite
{"tool": "read_file", "path": "large_file.log"}  // ‚ùå Malgasta tokens
```

**‚úÖ HAZ ESTO:**
```json
// Leer con l√≠mite inteligente
{"tool": "read_file", "path": "large_file.log", "max_lines": 50, "mode": "head"}  // ‚úÖ
```

**‚ùå NO HAGAS:**
```json
// M√∫ltiples operaciones individuales
write_file("file1.txt", ...)
write_file("file2.txt", ...)
write_file("file3.txt", ...)  // ‚ùå Sin atomicidad
```

**‚úÖ HAZ ESTO:**
```json
// Una operaci√≥n batch at√≥mica
{
  "tool": "batch_operations",
  "operations": [
    {"type": "write", "path": "file1.txt", ...},
    {"type": "write", "path": "file2.txt", ...},
    {"type": "write", "path": "file3.txt", ...}
  ],
  "atomic": true  // ‚úÖ Todo o nada
}
```

**‚ùå NO HAGAS:**
```json
// Edit directo sin analizar
edit_file(path, old_text, new_text)  // ‚ùå Puede fallar
```

**‚úÖ HAZ ESTO:**
```json
// Analiza primero, luego edita
1. analyze_edit(path, old_text, new_text)  // ‚úÖ Ver qu√© pasar√°
2. Si OK ‚Üí edit_file(...)
```

### üí° Tips de Eficiencia

1. **Para logs**: Siempre usa `mode="tail"` para ver entradas recientes
2. **Para c√≥digo**: Usa `mode="head"` para ver imports/estructura
3. **Para debugging**: Usa `mode="all"` para overview r√°pido
4. **Para refactoring**: SIEMPRE usa `batch_operations` con validaci√≥n
5. **Para eliminaciones**: Prefiere `soft_delete_file` sobre `delete_file`

### üìä M√©tricas de √âxito

**Token Usage √ìptimo:**
- Lectura de archivo 1000 l√≠neas: ~2,500 tokens (con max_lines=100)
- Operaci√≥n batch (5 ops): ~500 tokens
- Session t√≠pica (100 ops): ~13,000 tokens

**Si usas m√°s tokens:**
- Revisa si est√°s usando `max_lines`
- Verifica que uses batch operations
- Confirma que lees progresivamente

### üéØ Regla de Oro

**"Empieza peque√±o, escala solo si necesitas"**

- 20-50 l√≠neas para contexto inicial
- 100 l√≠neas si necesitas m√°s detalle
- Sin l√≠mite solo como √∫ltimo recurso

### üîß Configuraci√≥n del Usuario

Este MCP est√° configurado con:
- `--compact-mode`: Respuestas optimizadas
- `--max-search-results`: 20
- `--max-list-items`: 50

**Resultado esperado:** 80-90% reducci√≥n de tokens vs baseline

---

## üéì Recuerda Siempre

1. ‚úÖ `max_lines` es tu amigo - √∫salo siempre
2. ‚úÖ `batch_operations` para cambios m√∫ltiples
3. ‚úÖ `analyze_*` antes de operaciones cr√≠ticas
4. ‚úÖ Lectura progresiva (peque√±o ‚Üí grande)
5. ‚úÖ `intelligent_*` herramientas por defecto
6. ‚úÖ `soft_delete` mejor que `delete`
7. ‚úÖ Valida antes de ejecutar batches

---

**Con estas instrucciones, usar√°s este MCP de forma √≥ptima, ahorrando tokens y siendo m√°s eficiente.**
